[
{"tokens": ["It", "serves", "crepes", "in", "hardy", "sizes", ",", "sizes", "that", "I", "'ve", "never", "seen", "before", ",", "even", "in", "Paris", "."], "e1_text": "serves", "e1_pos": 1, "e2_text": "'ve", "e2_pos": 10, "label": "before"}
]
