[
{"tokens": ["It", "'s", "a", "little", "bit", "of", "the", "old", "Arizona", "that", "existed", "before", "everything", "was", "homogenized", "and", "sanitized", "into", "uniformity", "."], "e1_text": "existed", "e1_pos": 10, "e2_text": "was", "e2_pos": 13, "label": "before"}
]
