[
{"tokens": ["It", "may", "just", "be", "me", "and", "that", "my", "stomache", "can", "not", "handle", "rare", "meat", "but", "there", "'s", "no", "way", "I", "can", "give", "it", "a", "decent", "mark", "since", "I", "basically", "flushed", "$", "38", "down", "the", "toilet", "so", "soon", "after", "eating", "here", "."], "e1_text": "flushed", "e1_pos": 29, "e2_text": "eating", "e2_pos": 38, "label": "after"}
]
