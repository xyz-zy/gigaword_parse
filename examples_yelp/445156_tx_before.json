[
{"tokens": ["It", "makes", "up", "for", "the", "''", "``", "Jerk", "Tofu", "''", "''", "which", "I", "am", "afraid", "to", "say", "is", "not", "authentic", "at", "all", ",", "i", "never", "saw", "it", "before", "I", "came", "here", "."], "e1_text": "saw", "e1_pos": 25, "e2_text": "came", "e2_pos": 29, "label": "before"}
]
